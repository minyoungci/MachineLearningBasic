{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bdd3a16",
   "metadata": {},
   "source": [
    "### stratified K 폴드 \n",
    "\n",
    "stratified K 폴드는 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K 폴드 방식. \n",
    "가령 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fec656ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data , columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c39883fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "##교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "##교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('##교차 검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f531e4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "##교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "##교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df , iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('##교차 검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n', label_test.value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f28c857",
   "metadata": {},
   "source": [
    "## 교차 검증을 조금 더 편하게 해주는 API : cross_val_score()\n",
    "\n",
    "cross_val_score() 은 KFold의 과정인 폴드세트 설정, for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스 추출 및 반복적인 학습과 예측 수행 및 예측 성능 반환을 한 번에 수행.\n",
    "\n",
    "corss_val_score() API로 내부에서 Estimator를 학습(fit), 예측(predict), 평가(evaluation) 시켜주므로 간단하게 교차 검증을 수행할 수 있슴. \n",
    "\n",
    "corss_val_score()는 하나의 평가 지표만 가능하지만, corss_validate() 는 여러 개의 평가 지표를 반환 가능 \n",
    "\n",
    "보통 corss_val_score() 하나로도 대부분의 경우 쉽게 사용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a729821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도:  [0.98 0.94 0.98]\n",
      "평균 검증 정확도:  0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate \n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도 (accuracy) , 교차 검증 세트는 3개 \n",
    "# cross_val_score 의 주요 파라미터 - estimator(Classifier or Regression), x (feature data set), y (label data set), \n",
    "# scoring (에측 성능 지표 ), cv(교차 검증 폴드 수)\n",
    "\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "\n",
    "print('교차 검증별 정확도: ', np.round(scores, 4))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c3fe2",
   "metadata": {},
   "source": [
    "# GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에\n",
    "\n",
    "sklearn 에서 GridSearchCV API를 이용해 Classifier 이나 Regressor과 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안을 제공합니다. Grid는 격자라는 뜻으로 촘촘하게 파라미터를 순차적으로 변경하면서 최고 성능을 가지는 파라미터 조합을 찾고자 한다면 다음과 같이 파라미터의 집합을 만들고 이를 순차적으로 적용하면서 최적화 수행이 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cff7cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = {'max_depth: ': [1,2,3],\n",
    "                  'min_depth' : [2,3]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d4f244",
   "metadata": {},
   "source": [
    "### GridSearchCV 클래스의 생성자로 들어가는 주요 파라미터 \n",
    "\n",
    "1. estimator : classifier, regressor, pipeline \n",
    "2. param_grid : key + 리스트 값을 가지는 딕셔너리가 주어짐. estimator의 튜닝을 위해 파라미터명과 사용될 여러 파라미터 값을 지정.\n",
    "3. scoring : 예측 성능을 측정할 평가 방법을 지정합니다. 보통은 사이킷런의 성능 평가 지표를 지정하는 문자열(예- 정확도의 경우 'accuracy')로 지정하나 별도의 성능 평가 지표 함수도 지정할 수 있음.\n",
    "4. cv : 교차 검증을 위해 분할되는 학습/테스트 세트의 개수를 지정 \n",
    "5. refit : 디폴트가 True 이며, True로 생성 시 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습 시킵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81b1b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터:  {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도:0.9750 \n",
      "테스트 데이터 세트 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# 붓꽃 데이터를 이용해 GridSearchCV 실습 \n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터를 로딩하고 학습 데이터와 테스트 분리\n",
    "\n",
    "iris = load_iris()\n",
    "label = iris.target \n",
    "data = iris.data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, label, test_size=0.2, random_state=121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "### 파라미터를 딕셔너리 형태로 설정 \n",
    "\n",
    "parameters = {'max_depth': [1,2,3], 'min_samples_split': [2,3]}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# param_grid 의 하이퍼 파라미터를 3개의 train, test set fold 롤 나누어 테스트 수행 설정.\n",
    "### refit = True 가 default임. True 이면 가장 좋은 파라미터 설정으로 재학습시킴.\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree, param_grid = parameters, cv=3, refit=True)\n",
    "\n",
    "# 붓꽃 학습 데이터로 param_grid 의 하이퍼 파리미터를 순차적으로 학습 / 평가\n",
    "\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridsearchCV 객체의 fit()을 수행하면 최고 성능을 나타낸 하이퍼 파라미터의 값과 그때의 평가 결과 값이 각각 best_params_ , best_score_ 속성에 기록됌.\n",
    "# GridSearchCV 결과를 추출해 DataFrame 으로 변환 \n",
    "\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]\n",
    "\n",
    "# cv_results_ : gridsearchcv 의 결과 세트로서 딕셔너리 형태로 key값과 리스트 형태의 value 값을 가집니다.\n",
    "\n",
    "print('GridSearchCV 최적 파라미터: ', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{0:.4f} '.format(grid_dtree.best_score_))\n",
    "\n",
    "# GridSearchCV의 refit으로 이미 학습된 estimator 반환 \n",
    "\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요 없음.\n",
    "\n",
    "pred = estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
